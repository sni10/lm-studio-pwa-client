# LM Studio PWA Client

Lightweight Progressive Web App client for [LM Studio](https://lmstudio.ai/) local AI server.

## Features

- 🚀 **Single HTML file** - no build process required
- 📱 **PWA ready** - install as mobile app  
- 🔄 **Real-time streaming** - live responses with thinking process
- 💾 **Persistent storage** - saves chat history and settings
- 🎨 **Mobile optimized** - responsive design with touch support
- 🌐 **Multi-model support** - works with any LM Studio compatible model

## Quick Start

1. Start LM Studio server on your local network
2. Open `index.html` in your browser
3. Configure server IP/port in settings (⚙️)
4. Select a model and start chatting

## Default Settings

- **Host**: `192.168.31.100`
- **Port**: `1234`
- **Max tokens**: `2048`
- **Temperature**: `0.7`

## Recent Improvements

- ✅ Model selection now persists between sessions
- ✅ Improved token counting with fallback estimation
- ✅ Better streaming response handling

---

*Simple, fast, and reliable LM Studio client that just works.*